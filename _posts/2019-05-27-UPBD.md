---
layout: post
title: "[2019 CVPR] Unsupervised Part-Based Disentangling of Object Shape and Appearance (*incomplete*)"
date: 2019-05-27 18:00:00
tags: CV unsupervised disentangled
---

<!--more-->

---

**Table of content** (*full-version*)
[[paper]](https://arxiv.org/pdf/1903.06946.pdf) [[project page]](https://compvis.github.io/unsupervised-disentangling/)
{: class="table-of-content"}
* TOC
{:toc}

---

## Summary

<br/>
![picture]({{ '/assets/images/UPBD01.png' | relative_url }})
{: style="width: 60%;" class="center"}
<span style="color: #e01f1f;">***Fig. 1. 요약***</span>

- Unsupervised 방식(파트정보 x, label x)으로 물체의 파트를 분할하여 모양과 외형을 분리하는 방법
- 여러가지 응용에서 사용가능
  - Shape: interpretable shape representation, shape transfer, landmark discovery
  - Appearance: local appearance transfer, video-to-video translation
- image pair 대신에 인위적인 변형으로 a/p를 구분할 수 있다는 장점

---

## Architecture

<br/>
![picture]({{ '/assets/images/UPBD02.png' | relative_url }})
{: style="width: 100%;" class="center"}
<span style="color: #e01f1f;">***Fig. 2. 전체 프레임워크***</span>


<p align="center">
[Notation]
</p>

{: class="info"}
| Symbol | Mean |
| ---------- | ---------- |
| $$a(x)$$ | image transformation (changes in brightness, contrast, hue) |
| $$s$$ | spatial image transformation (thin plate spline transformation) |
| $$\phi(x) := (\phi_1 (x), \phi_2 (x), ... )^T$$ | part-based factorization |
| $$\phi_i (x) = (\alpha_i (x), \sigma_i (x))$$ | disentangled representation |
| $$\alpha_i (x)$$ | part appearance (feature vector) |
| $$\sigma_i (x)$$ | part shape (activation map) |
| $$\mathit{E}_\alpha$$ | appearance hourglass network |
| $$\mathit{E}_\sigma$$ | shape hourglass network |
| $$\mathit{D}$$ | decoder |
| ---------- | ---------- |

- Two constraints
  - Invariance: $$\sigma_i (a(x)) = \sigma_i (x)$$ and $$\alpha_i (x \circ s) = \alpha_i (x)$$
  - Equivariance: $$\sigma_i (x \circ s) = \sigma_i (x) \circ s$$
- Shape stream
  - 영상의 appearance 변해도 shape 관련 특징 유지 (invariant to appearance): $$\sigma_i (a(x)) = \sigma_i (x)$$
- Appearance stream
  - 영상의 shape 변해도 appearance 관련 특징 유지 (invariant to shape): $$\alpha_i (x \circ s) = \alpha_i (x)$$
- Decoder
- Equivalance loss
  - 영상의 shape 변화시키면 shape 관련 특징도 그만큼 변화
- Reconstruction loss: $$L_{rec} = \left \| x - D([\alpha_i (x \circ s), \sigma_i (a(x))]_{i=1,...} \right \|$$
  - Invariance constraint 하에서 복원이 잘 되는지

---
  
## Experimental results

- 파트의 수를 정하는 것은 중요하다. 
- Landmark를 regression을 위한 분야가 아닌 이미지 합성을 하는 task에서는 영상을 진짜같이 만드는 것이 중요하므로 decoder에 adversarial loss를 추가한다. (real/fake 판단)


<br/>
![picture]({{ '/assets/images/UPBD03.png' | relative_url }})
{: style="width: 80%;" class="center"}
<span style="color: #e01f1f;">***Fig. 3. Unsupervised landmark discovery***</span>


<br/>
![picture]({{ '/assets/images/UPBD04.png' | relative_url }})
{: style="width: 80%;" class="center"}
<span style="color: #e01f1f;">***Fig. 4. 사람의 Pose/appearance 디코딩 시각화(이미지)***</span>


- Video-to-video translation
  - Temporal consistency constraint가 없는데도 불구하고 시간축으로 움직임이 부드러우며 강인하다.

<br/>
![picture]({{ '/assets/images/UPBD05.png' | relative_url }})
{: style="width: 80%;" class="center"}
<span style="color: #e01f1f;">***Fig. 5. 사람의 Pose/appearance 디코딩 시각화(비디오)***</span>


<br/>
![picture]({{ '/assets/images/UPBD06.png' | relative_url }})
{: style="width: 80%;" class="center"}
<span style="color: #e01f1f;">***Fig. 6. 사람의 일부 part만 변형 시각화***</span>

- Re-identification 으로의 적용
  - Pretrained Inception-Net with [2] via triplet loss to Deep fashion DB
  - Test set도 deep fashion
  - VU-NET은 supervised 방식

<br/>
![picture]({{ '/assets/images/UPBD07.png' | relative_url }})
{: style="width: 60%;" class="center"}
<span style="color: #e01f1f;">***Fig. 7. Re-Identification으로의 적용 결과***</span>

---

## Comments

---

## References

[1] Lorenz, Dominik, et al. "Unsupervised Part-Based Disentangling of Object Shape and Appearance." arXiv preprint arXiv:1903.06946 (2019).

[2] T. Xiao, S. Li, B. Wang, L. Lin, and X. Wang. Joint detection and identification feature learning for person search. In
CVPR. IEEE, 2017.
