---
layout: post
title: "[2019 CVPR] Dissecting Person Re-identification from the Viewpoint of Viewpoint"
date: 2019-07-08 21:00:00
tags: CV re-id
---

<!--more-->

---

**Table of content** (*full-version*)
[[paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Sun_Dissecting_Person_Re-Identification_From_the_Viewpoint_of_Viewpoint_CVPR_2019_paper.pdf) [[github]](https://github.com/sxzrt/Dissecting-Person-Re-ID-from-the-Viewpoint-of-Viewpoint)
{: class="table-of-content"}
* TOC
{:toc}

---

## Summary

- Viewpoint(pedestrian rotation angle)에 대한 고찰
- 기존에 있는 dataset으로 viewpoint를 분석할 때 문제점
  - 데이터의 양이 부족 (사람마다 viewpoint가 한정적, fixed/static)
  - 다른 시각적 요소들이 완전이 배제된 채 오로지 viewpoint에 대한 고찰 불가 (실제 데이터셋은 시각적 요소 복합적으로 적용) 
- PersonX: large-scale synthetic data engine
  - 1266명의 수동으로 제작된 identity
  - Controllable (여러가지 시각적 조건 조작 가능)
  - 정확한 bounding box (Detection error에 영향을 받지 않음)
- 실험 방법
  - PersonX와 다른 기존 데이터셋들에서 reid 방법들이 성능 경향이 어느정도 일치하는지 확인
  - Viewpoint가 수동적으로 레이블링된 real-world Market-1203에서 경험적으로 연구
- 연구의 목적
  - Training set / Gallery set / Probe set을 디자인 하는 방법 제시


<br/>
<p align="center" style="color: #e01f1f; font-weight: bold;">[Viewpoint에 대한 설명]</p>
![picture]({{ '/assets/images/PERSONX01.png' | relative_url }}){: style="width: 70%;" class="center"}
<br/>

---

## Description

- Summary
  - Total number of images: 36 angles $$\times$$ 1266 identities $$\times$$ 6 cameras
  - Resolution: 1024 $$\times$$ 768 (default), 512 $$\times$$ 242 (low-resolution)
  - Evaluation: training (410 identities) and testing (856 identities, query $$\rightarrow$$ one image per camera for each identity)
- Identities
  - Diversity(1266 identities): skin color, ages, body forms (height and weight), hair styles, clothes (mapped from real-world image), carrying, motion (walking, running, standing, having a dialogue)
- Visual factors
  - Viewpoint(36 angles): 36 different angles, 4 orientation (clustered, see the first figure)
  - Camera(6 backgrounds): illumination changes (sun light, point light, spotlight, area light), camera (image resolution, projection, focal length, height), background (uniform colors, street scenes)
    - (1) white background
    - (2) gray background (similar to 1)
    - (3) black background (not similar 1)
    - (4) street scene
    - (5) street scene, different background (similar to 4)
    - (6) street scene, different ground color (gray) and shadowed region (not similar to 4)
    
<br/>
<p align="center" style="color: #e01f1f; font-weight: bold;">[PERSONX 데이터셋에서 viewpoint 변화에 대한 예시]</p>
![picture]({{ '/assets/images/PERSONX03.png' | relative_url }}){: style="width: 70%;" class="center"}
<br/>

<br/>
<p align="center" style="color: #e01f1f; font-weight: bold;">[PERSONX 데이터셋에서 배경/카메라/옷 변화에 대한 예시]</p>
![picture]({{ '/assets/images/PERSONX02.png' | relative_url }}){: style="width: 100%;" class="center"}
<br/>

---
  
## Benchmarking and data validation

- Data validation
  - Eliglibility(적격): $$PCB > triplet \approx IDE+$$ performance trend is similar to that of real-world dataset
  - Purity(순도): High-resolution, normal sunlight, relatively consistent background $$\rightarrow$$ high accuracy compared to real-world datasets $$\rightarrow$$ ideal ones for studying the impact of viewpoints
  - Sensitivity(민감도): PersonX subsets are sensitive to background complexity (see the second below figure)
- Datasets
  - Difficulty
    - $$PersonX_{12} < PersonX_{13}$$: color difference
    - $$PersonX_{45} < PersonX_{46}$$: background difference
    - $$PersonX_{123} < PersonX_{456}$$: more complex background
    - $$PersonX_{456} < PersonX_{456}-lr$$: less information
  - Existing synthetic datasets
    - SyRI, SOMAset

<br/>
<p align="center" style="color: #e01f1f; font-weight: bold;">[PERSONX 데이터셋의 종류]</p>
![picture]({{ '/assets/images/PERSONX04.png' | relative_url }}){: style="width: 70%;" class="center"}
<br/>


<br/>
<p align="center" style="color: #e01f1f; font-weight: bold;">[데이터셋의 종류에 따른 성능]</p>
![picture]({{ '/assets/images/PERSONX05.png' | relative_url }}){: style="width: 100%;" class="center"}
<br/>

---
  
## Evaluation of viewpoint

### How do viewpoint distributions in the ***training set*** affect model learning?
- Summary
  - 성능(Viewpoint 무작위 삭제) $$>$$ 성능(연속되는 Viewpoint 삭제)
  - 제한된 viewpoint만 학습할 수 있다면 left/right를 위주로 학습하는게 낫다.



- Control group
  - 
  
  
<br/>
<p align="center" style="color: #e01f1f; font-weight: bold;">[Training set에서 control group 예시]</p>
![picture]({{ '/assets/images/PERSONX11.png' | relative_url }}){: style="width: 100%;" class="center"}
<br/>

- Experimental group





<br/>
<p align="center" style="color: #e01f1f; font-weight: bold;">[Training set에서 viewpoint의 부재 실험]</p>
![picture]({{ '/assets/images/PERSONX06.png' | relative_url }}){: style="width: 100%;" class="center"}
<br/>

<br/>
<p align="center" style="color: #e01f1f; font-weight: bold;">[Training set에서 일부 viewpoint에서만 학습]</p>
![picture]({{ '/assets/images/PERSONX07.png' | relative_url }}){: style="width: 70%;" class="center"}
<br/>



### How does ***query*** viewpoint affect retrieval?
- Summary
  - 성능(Left/right의 viewpoint를 갖는 query) $$>$$ 성능(front/back의 viewpoint를 갖는 query)


 
<br/>
<p align="center" style="color: #e01f1f; font-weight: bold;">[Query 실험에서 true match 예시]</p>
![picture]({{ '/assets/images/PERSONX13.png' | relative_url }}){: style="width: 100%;" class="center"}
<br/>



<br/>
<p align="center" style="color: #e01f1f; font-weight: bold;">[Query의 viewpoint 변화에 따른 성능]</p>
![picture]({{ '/assets/images/PERSONX08.png' | relative_url }}){: style="width: 70%;" class="center"}
<br/>




### How do true match viewpoints in the ***gallery*** affect retrieval?
- Summary
  - Query에 해당하는 gallery의 true match가 다른 viewpoint인 경우 query의 viewpoint와 비슷한 viewpoint를 갖는 다른 사람으로 매칭될 가능성이 높다.
  - 환경이 악화(complex background, extreme illumination, low resolution)되면 이런 문제가 더 크게 발생한다.


- Control group
  - 
  
 
- Experimental group

 
<br/>
<p align="center" style="color: #e01f1f; font-weight: bold;">[Gallery 실험에서 control group, experimental group 예시]</p>
![picture]({{ '/assets/images/PERSONX12.png' | relative_url }}){: style="width: 100%;" class="center"}
<br/>



<br/>
<p align="center" style="color: #e01f1f; font-weight: bold;">[Query와 true match사이에 존재하는 viewpoint disparity의 영향]</p>
![picture]({{ '/assets/images/PERSONX09.png' | relative_url }}){: style="width: 70%;" class="center"}
<br/>


<br/>
<p align="center" style="color: #e01f1f; font-weight: bold;">[Market-1203에서의 gallery 실험 예시]</p>
![picture]({{ '/assets/images/PERSONX10.png' | relative_url }}){: style="width: 70%;" class="center"}
<br/>



---

## Comments

---

## References

[1] Sun, Xiaoxiao, and Liang Zheng. "Dissecting Person Re-identification from the Viewpoint of Viewpoint." Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019.
