---
layout: post
title: "[2019 CVPR] GCAN: Graph Convolutional Adversarial Network for Unsupervised Domain Adaptation"
date: 2019-07-10 18:00:00
tags: CV 
---

<!--more-->

---

**Table of content** (*short-version*)
[[paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Ma_GCAN_Graph_Convolutional_Adversarial_Network_for_Unsupervised_Domain_Adaptation_CVPR_2019_paper.pdf)
{: class="table-of-content"}
* TOC
{:toc}

---

## Summary

- Unsupervised DA에 graph를 도입하여 최고 성능
- Source와 target의 격차 줄이기 위해서는 data structure, domain label, class label을 이용해야 함
- 기존 2018 ICML 방식은 data structure를 고려하지 않음

- 2018 ICML 구조와 비슷한데 GCN 만 추가
- 구조적 점수를 뽑은 다음에 A를 형성, feature와 함께 GCN에 넣음
- 뒷단은 기존과 동일
- Loss 4가지
  - Classification: source의 cross entropy loss
  - Domain alignment: 데이터가 source에서 왔는지 target에서 왔는지 모르도록 학습
  - Structure aware alignment: batch 단위로 source 정보에서 label 별로 비슷한 structure 추출하도록 triplet loss 형성
  - Class centroid alignment: 같은 label 인경우 feature 비슷하도록 (euclidean distance)
  
- 기존에 DA에 비해서 좋은 성능
- Graph 논문보면 GCN은 매우 얉게 구성 (높이면 성능이 떨어짐)
- GCN layer 1개만 사용



- 데이터가 S에서 왔는지 T에서 왔는제 헷갈리게 하여 global distribution 매칭 (class 끼리 매칭이 잘 안될 수 있다)
- 클래스와 수도레이블을 가지고 class 끼리 분포를 비슷하게 하고
- 마지막으로 구조적 정보를 이용하여 이또한 매칭시킨다.
  
  
<br/>
<p align="center" style="color: #e01f1f; font-weight: bold;">[Motivation]</p>
![picture]({{ '/assets/images/GCAN01.png' | relative_url }}){: style="width: 70%;" class="center"}
<br/>

<br/>
<p align="center" style="color: #e01f1f; font-weight: bold;">[전체 프레임워크]</p>
![picture]({{ '/assets/images/GCAN02.png' | relative_url }}){: style="width: 100%;" class="center"}
<br/>

<br/>
<p align="center" style="color: #e01f1f; font-weight: bold;">[Transfer 결과]</p>
![picture]({{ '/assets/images/GCAN03.png' | relative_url }}){: style="width: 100%;" class="center"}
<br/>


---


## References

[1] Ma, Xinhong, Tianzhu Zhang, and Changsheng Xu. "GCAN: Graph Convolutional Adversarial Network for Unsupervised Domain Adaptation." Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019.
