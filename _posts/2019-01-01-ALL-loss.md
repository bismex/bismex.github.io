---
layout: post
title: "ALL about loss function (ongoing..)"
date: 2019-01-01 12:00:00
tags: ML
---

<!--more-->

---

**Table of content** (*full-version*)
[[paper]]() [[github]]()
{: class="table-of-content"}
* TOC
{:toc}

---

https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/
https://towardsdatascience.com/common-loss-functions-in-machine-learning-46af0ffc4d23

## Regression loss function

### Mean Squared Error (quadratic / L2)

### Mean Absolute Error (L1)

### Mean Bais Error

### Mean Squared Logarithmic Error

### Smooth Absolute error


## Binary classification loss function

### Binary Cross-Entropy (Negative Log Likelihood)

### Hinge (Multi-class SVM)

### Squared Hinge

### Contrastive 

## Multi-class classification loss function

### Multi-Class Cross-Entropy 

### Sparse Multiclass Cross-Entropy 

### Kullback Leibler Divergence 


## ETC

### Logistic loss




---
