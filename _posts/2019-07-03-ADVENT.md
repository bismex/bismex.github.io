---
layout: post
title: "[2019 CVPR] ADVENT: Adversarial Entropy Minimization for Domain Adaptation in Semantic Segmentation"
date: 2019-07-03 18:00:00
tags: CV AE DA segmentation
---

<!--more-->

---

**Table of content** (*short-version*)
[[paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Vu_ADVENT_Adversarial_Entropy_Minimization_for_Domain_Adaptation_in_Semantic_Segmentation_CVPR_2019_paper.pdf) [[github]](https://github.com/valeoai/ADVENT)
{: class="table-of-content"}
* TOC
{:toc}

---

## Summary

- Semantic segmentation 논문
- Unsupervised domain adaptation 적용 논문
- Entropy에 대한 direct/adversarial 학습을 통해 semantic segmentation 문제를 해결
  - Source에서 sementic segmentation과정을 학습하면 높은 prop을 가진 결과를 추정 (entropy가 낮음)
  - 하지만 이를 adaptation없이 source에서 학습된 model로 추정을 하면 segmentation 결과가 좋지 않음 (entropy 높음)
  - 따라서, entropy를 줄이는 방식으로 unsupervised DA를 적용하여 학습
  

<br/>
<p align="center" style="color: #e01f1f; font-weight: bold;">[Motivation]</p>
![picture]({{ '/assets/images/ADVENT01.png' | relative_url }}){: style="width: 70%;" class="center"}
<br/>

<br/>
<p align="center" style="color: #e01f1f; font-weight: bold;">[전체 프레임워크]</p>
![picture]({{ '/assets/images/ADVENT02.png' | relative_url }}){: style="width: 100%;" class="center"}
<br/>


- Entropy minimization은 기존에도 많이들 사용하는 방식
- Direct entropy minimization
  - Shannon entropy이용, 정규화, 엔트로피 직접적으로 최소화하는 방법, P에 1/C 넣어주면 결과적으로 1이 나와서 최대가 됨
  - Source에서 supervised loss와 direct entropy loss를 조합
  - Self training 관점에서 해석:  pseudo label을 사용하는데 soft assignment를 해준 것과 같음
- Minimizing entropy with adversarial learning
  - Direct entropy minimization에서 summation 과정 때문에 spatial 유지 부분 문제
  - Segmentation output을 entropy map으로 변환시켜준 다음에 이를 discriminator에 넣음
  - Source와 target의 entropy가 비슷해지도록 학습
- Entropy를 잘 이용하면 다른 task에서도 잘 사용할 수 있을 것
- Detection 쪽에서도 활용한 것을 실험함

---


## References

[1] Vu, Tuan-Hung, et al. "Advent: Adversarial entropy minimization for domain adaptation in semantic segmentation." Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019.
