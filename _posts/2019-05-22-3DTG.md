---
layout: post
title: "[2019 CVPR] Re-Identification Supervised Texture Generation"
date: 2019-05-22 22:00:00
tags: CV re-id generative-model supervised gan 3d
---

<!--more-->

{: class="table-of-content"}
* TOC
{:toc}


## Summary

- Re-identification의 supervision 하에 사람의 텍스쳐를 3D 형태로 생성하는 end-to-end network
- Re-identification network는 perceptual metrics로써 사용 

## Motivation

- Single image에서 textured 3D model을 생성하는 것은 challenging issue (occlusion and background texture 문제)
- 이 문제들을 해결하기 위해서 re-identification의 supervision을 이용 
  - Re-identification에서는 다른 시점에서도 texture를 보고 알아맞춤 $$\rightarrow$$ occlusion 문제 해결가능
  - Re-identification에서는 background clutter에 상관 없이 사람에 대한 특징을 잘 추출함 $$\rightarrow$$ background texture 문제 해결가능

## Architecture

![picture]({{ '/assets/images/3DTG000.png' | relative_url }})
{: style="width: 100%;" class="center"}

- 따로 GAN-style discriminator와 loss를 결합하지 않는 이유는 rendered 이미지와 실제 이미지와 명확한 스타일 gap이 있기 때문이다. (D가 real/fake 구분하기 너무 쉬움)
- HMR[2]: 3d body pose and shape estimation (iterative 3D regression module) $$\rightarrow$$ shape $$\beta$$ 10dim, pose $$\theta$$ 72dim, translation $$\gamma$$ 3dim, K=23joints 
- SMPL[3]: shape, pose, translation parameters $$\rightarrow$$ 3차원의 N=6890 vertices로 삼각형의 몸통 mesh 형성 (미분가능) 
- Opendr[4]: differentiable renderer, pre-processing
- Re-ID loss: rendered image $$y$$와 input image $$x$$가 pre-trained re-id network(PCB[5] 사용)를 통과하면서 1~4번째까지의 feature activation에 대한 L2 차이를 이용한다. 즉, low, mid, high-level feature statistics 비교하는 것이다. 같은 사람일 경우 해당 loss를 최소화하며, 다른 사람이면 최대화한다. 
- Face loss: 얼굴과 팔부분에 대해서 U-Net에 의해서 생성된 텍스처와 SURREAL[6]로 부터 3D scanning된 텍스처 사이의 L1 loss. 

## Experimental results

- Dataset: Market-1501
- Metric: SSIM, Mask-SSIM
- Face loss ablation
  - Pasted face: 바로 SURREAL에서 추출한 텍스처를 쓰지 않는 이유는 머리와 몸통 사이의 색 대조를 맞추기 위함이다.
  
![picture]({{ '/assets/images/3DTG001.png' | relative_url }})
{: style="width: 70%;" class="center"}

- Re-ID loss ablation 1
  - Perceptual loss: ImageNet 통과한 것이며 바디 텍스쳐만을 보기 보다는 전반적인 텍스쳐를 맞추는 경향이 있어서 안 좋다.
  - Pixelwise-L1 loss: HMR과정에 의존적이라서 체형이 맞지 않으면 안좋다. 
  
![picture]({{ '/assets/images/3DTG002.png' | relative_url }})
{: style="width: 70%;" class="center"}
  
- Re-ID loss ablation 2
  - 
  
![picture]({{ '/assets/images/3DTG003.png' | relative_url }})
{: style="width: 70%;" class="center"}
  

## Comments

- 따로 HMR이나 SMPL는 학습을 하지 않는 것으로 보이는데 여기에서 극복할 수 없는 한계가 보이는듯. (포즈가 다르면..?)

## References

[1] Wang, Jian, et al. "Re-Identification Supervised Texture Generation." arXiv preprint arXiv:1904.03385 (2019).

[2] 25

[3] 36

[4] 37

[5] 46

[6] 50
