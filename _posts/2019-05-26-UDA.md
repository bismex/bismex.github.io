---
layout: post
title: "[2019 CVPR] Universal Domain Adaptation"
date: 2019-05-26 17:40:00
tags: ML domain-adaptation
---

<!--more-->

---

**Table of content** (*short-version*)
[[paper]](http://ise.thss.tsinghua.edu.cn/~mlong/doc/universal-domain-adaptation-cvpr19.pdf) [[github]](https://github.com/thuml/Universal-Domain-Adaptation)
{: class="table-of-content"}
* TOC
{:toc}

---

## Summary

- UDA(source domain만 알고 target domain는 전혀 모름) 개념 도입

---

## Motivation

- DA는 존재하는 prior knowledge를 이용하여 domain gap을 줄이는 것이 목표이다.
- DA는 어려가지로 분류할 수 있는데, 일반화가 안 되어있다.
- Patial DA에서 학습한 모델을 closed DA에 적용하면 잘 안된다.
- Source와 target의 label관계에 대한 prior knowledge가 전혀 없는 가장 일반화된 DA가 필요하다.

<br/>
![picture]({{ '/assets/images/UDA01.png' | relative_url }})
{: style="width: 50%;" class="center"}
<span style="color: #e01f1f;">
<br/>
***Fig. 1. Universal domain adaptaion의 개념***</span>

---

## Architecture

- 전체 프레임워크
  - 파란색이 새롭게 제안한 네트워크
  - G: classifier
  - D: S인지 T인지 구분
  - D': 입력 영상이 S와 얼마나 가까운지 판단
  - 이 네트워크는 sample-level transferability를 수량화하여 common label set을 발견하고 이를 각 도메인에 전용으로 설정한다.
  - 이로써 자동으로 발견된 common label set에서 adaptation을 촉진하고, unknown sample인지를 성공적으로 인식한다.
  - Domain similarity와 prediction uncertainty를 정의하고 이 값에 따라서 weight $$w^s, w_t$$를 구한다.
  - 추정할 target label이 source에 포함된 label(common label)이면 분류하고 아니면 unknown으로 판단해야한다.
  - 얼마나 레이블을 공유하는지에 대한 variable을 정의하고 UDA는 이 변수 값에 관계없이 성능이 잘 나와야 한다.
  
![picture]({{ '/assets/images/UDA02.png' | relative_url }})
{: style="width: 100%;" class="center"}
<span style="color: #e01f1f;">
<br/>
***Fig. 2. 전체 프레임워크 (UAN)***</span>

---
  
## Experimental results

<br/>
![picture]({{ '/assets/images/UDA03.png' | relative_url }})
{: style="width: 100%;" class="center"}
<span style="color: #e01f1f;">
<br/>
***Fig. 3. 실험 결과***</span>


---

## References

[1] You, Kaichao, et al. "Universal Domain Adaptation."

