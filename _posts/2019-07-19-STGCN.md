---
layout: post
title: "[2018 AAAI] Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition"
date: 2019-07-19 12:00:00
tags: pose video semi CV GCN 
---

<!--more-->

---

**Table of content** (*full-version*)
[[paper]](https://arxiv.org/pdf/1801.07455.pdf) [[github]](https://github.com/yysijie/st-gcn)
{: class="table-of-content"}
* TOC
{:toc}

---

## Summary


- Skeleton-based action recognition 논문 (포즈 추정 정보만 이용하여 행동을 이식하는 분야)
- Spatial-Temporal Graph Convolutional Networks (ST-GCN) 제안
  - 노드: body joints, feature vector (coordinate vectors + estimation confidence)
  - 엣지: spatial(intra-body edges, neighbor node <= 1), temporal(inter-frame edges, temporal kernel size = 9)
  - 그래프 관계: 각 joint마다 인접한 spatial, temporal joint set들을 분할
    - Unilabeling: same label
    - Distance: root node (0), neighbor nodes (1)
    - Spatial configuration: gravity center에서의 거리에 따라서 (0, 1, 2)


<br/>
<p align="center" style="color: #e01f1f; font-weight: bold;">[그래프 관계짓는 방법]</p>
![picture]({{ '/assets/images/STGCN02.png' | relative_url }}){: style="width: 100%;" class="center"}
<br/>
    
- Implementation
  - ST-GCN
    - Kipt and Welling method
    - For each A, including learnable weight matrix M (initialized as all-one matrix)
  - Architecture
    - Input: (3, 300, 18, 2) tensor, (#coordinates + confidence, #frames, #joints, #person)
    - Batch normalization, 9 ST-GCN (ResNet mechanism + dropout, 64/64/64/pooling/128/128/128/pooling/256/256/256 channels)
    - Output: 256-dim feature vector (applying grobal average pooling), Softmax
  - 8 TITANX GPU
  - Dataset: Kinetics, NTU-RGB+D


<br/>
<p align="center" style="color: #e01f1f; font-weight: bold;">[전체 아키텍처]</p>
![picture]({{ '/assets/images/STGCN01.png' | relative_url }}){: style="width: 100%;" class="center"}
<br/>


---

## References

[1] Yan, Sijie, Yuanjun Xiong, and Dahua Lin. "Spatial temporal graph convolutional networks for skeleton-based action recognition." Thirty-Second AAAI Conference on Artificial Intelligence. 2018.
