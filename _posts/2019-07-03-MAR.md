---
layout: post
title: "[2019 CVPR] Unsupervised Person Re-identification by Soft Multilabel Learning (*Incomplete*)"
date: 2019-07-03 15:00:00
tags: CV re-id unsupervised
---

<!--more-->

---

**Table of content** (*full-version*)
[[paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Yu_Unsupervised_Person_Re-Identification_by_Soft_Multilabel_Learning_CVPR_2019_paper.pdf) [[github]](https://github.com/KovenYu/MAR)
{: class="table-of-content"}
* TOC
{:toc}

---

## Summary

- Unsupervised person REID 분야 (sup reid는 scalability 문제 있음)
- Soft multilabel(SM) learning: (source 도메인의 unlabeled 사람)을 (auxiliary 도메인의 labeled 참조 사람들)과 비교함으로써 soft multilabel을 부여하는 방식 (pseudo label 대신에 real-valued likelihood vector) 

<br/>
![picture]({{ '/assets/images/MAR01.png' | relative_url }})
{: style="width: 60%;" class="center"}
<span style="color: #e01f1f;">***Fig. 1. Soft multilabel learning의 컨셉***</span>

- Deep Soft Multilabel reference learning (MAR) 안에 MDL, CML, RAL 포함
  - Soft multilabel-guided discriminative embedding learning (MDL): 시각적 관점과 상대비교 특성에 대한 representation consistancy를 기반으로 soft multilabel-guided hard negative mining을 수행하고, batch마다 pos/neg set을 확보하여 pos set은 서로 가까워지도록, neg set은 멀어지도록 embedding feature를 학습하는 방법.
  - Cross-view consistent soft multilabel learning (CML): 
  - Reference agent learning (RAL)
  

- Reference agent learning: 효율적인 SM 학습을 위해 joint feature embedding 안에서 참조 agent에 의한 참조 person을 나타내는 방식 

--- 

## Motivation

- 기존의 방법들
  - 기존의 unsupervised reid 방법은 시각정 특징의 유사도만 보는 반면 잠재적인 레이블 정보를 보조 데이터로부터 확보한다.
  - 기존에 unsupervised DA을 기반으로하는 방법 중에서, 보조 labeled source 도메인으로부터 분별력있는 지식을 target domain으로 옮기는 방식이 있는데 이는 unlabeled source와 unlabeled target 사이의 도메인 시프트가 발생한다.
  - 그리고 일반적인 unsupervised DA에서 사용하는 같은 클래스간의 변환은 reid task와 이와 적합하지 않다.
- 본 논문의 방법은 기존의 unsupervised DA 논문들과 다르게 unlabeled target domain의 분별력있는 정보를 캐지 않은채 보조 데이터를 이용한다.

---

## Architecture

- 전체 프레임워크: 3개의 loss term (MDL, CML, RAL) 사용

<br/>
![picture]({{ '/assets/images/MAR02.png' | relative_url }})
{: style="width: 100%;" class="center"}
<span style="color: #e01f1f;">***Fig. 2. 전체 프레임워크***</span>

<p align="center">
[Notation]
</p>

{: class="info"}
| Symbol | Mean |
| ---------- | ---------- |
| $$\mathcal{X}=\left \{ x_i \right \}^{N_u}_{i=1}$$ | unlabeled target REID dataset (Market1501, DukeMTMC-reID)|
| $$x_i$$ | unlabeled target image |
| $$N_u$$ | the number of target images |
| $$\mathcal{Z}=\left \{ z_i, w_i \right \}^{N_a}_{i=1}$$ | labeled auxiliary (reference) REID dataset (MSMT17 $$\rightarrow$$ #ID-4101, #Img-126441) |
| $$z_i$$ | reference image |
| $$w_i=1, ..., N_p$$ | reference person label |
| $$N_p$$ | the number of reference persons |
| $$N_a$$ | the number of reference images |
| $$\left \{ a_i \right \}^{N_p}_{i=1}$$ | reference agents |
| $$y=l(f(x), \left \{ a_i \right \}^{N_p}_{i=1}) \in (0, 1)^{N_p}$$ | soft multilabel |
| $$l(\cdot)$$ | soft multilabel function (label likelihood w.r.t. ref. person) |
| $$f(\cdot)$$ | deep feature embedding |
| $$A(\cdot, \cdot)$$ | soft multilabel agreement |
| ---------- | ---------- |

- Soft multilabel-guided discriminative embedding learning (MDL)
  - Unlabeled target domain에서 positive set은 서로 가까워지도록, negetive set은 멀어지도록 embedding feature를 학습하는 방법.
  - $$L_{MDL} = -\log \frac{\overline{P}}{\overline{P} + \overline{N}}$$
  - $$\overline{P} = \frac{1}{|\mathcal{P}|} \sum_{(i, j) \in \mathcal{P}} \exp (-\left \| f(z_i) - f(z_j) \right \|^2_2), \overline{N} = \frac{1}{|\mathcal{N}|} \sum_{(k, l) \in \mathcal{N}} \exp (-\left \| f(z_k) - f(z_l) \right \|^2_2)$$
  - SM-guided hard negative mining: unlabeled target 도메인에 대한 분별력있는 embedding feature $$f(\cdot)$$을 학습하는 방식. Unlabeled target pair $$(x_i, x_j)$$에서 시각적 특징 $$(f(x_i)^T f(x_j))$$과 soft multilabel agreement $$(A(y_i, y_j)=1-\frac{\left \| y_i - y_j \right \|_1}{2})$$을 보고 similarity consistency를 분석. 시각적으로 서로 유사하지만 (i.e., $$f(x_i)^T f(x_j)>=S$$) SM agreement이라는 다른 관점이 서로 다르다면 (i.e., $$A(y_i, y_j)<T$$) hard negative로 판단하고 두 관점 모두에서 영상이 비슷하면 positive set으로 판단. 한 batch (=368) 내에서 총 가능한 pair 수를 다음과 같이 표현할 때 (i.e., $$M=N_{batch} \times (N_{batch} - 1 )/2$$, $$N_{batch}$$는 한 batch 내에서 unlabeled target image의 수, 한 batch는 무작위로 샘플링한 $$x, z$$를 절반씩 구성), positive set와 negative set의 비율은 mining ratio $$p$$에 의해서 시각적으로 유사한 $$pM$$ pair 중에서 threshold $$T$$를 이용하여 조정. 여기에서 hypersphere leaning을 위해 $$\left \| f(\cdot) \right \|_2=1$$, $$\left \| a_i \right \|_2=1$$라고 가정 (하지만, 이는 수렴 문제 때문에 초기에는 unit norm constraint 없이 $$L_{AL}$$만 가지고 network 학습한다.).
  


<br/>
![picture]({{ '/assets/images/MAR03.png' | relative_url }})
{: style="width: 60%;" class="center"}
<span style="color: #e01f1f;">***Fig. 3. Soft multilabel-guided hard negative mining***</span>


<br/>
![picture]({{ '/assets/images/MAR04.png' | relative_url }})
{: style="width: 60%;" class="center"}
<span style="color: #e01f1f;">***Fig. 4. Soft multilabel-guided hard negative mining의 결과***</span>


- Cross-view consistent soft multilabel learning (CML): 
  - 요약) 이는 cross-view (cross-camera) consistent SM learning으로 발전시킴.
- Reference agent learning (RAL): 


---

## Experimental results


<br/>
![picture]({{ '/assets/images/MAR05.png' | relative_url }})
{: style="width: 60%;" class="center"}
<span style="color: #e01f1f;">***Fig. 5. Performance comparison (Market-1501, DukeMTMC-reID)***</span>


<br/>
![picture]({{ '/assets/images/MAR06.png' | relative_url }})
{: style="width: 60%;" class="center"}
<span style="color: #e01f1f;">***Fig. 6. Ablation study***</span>



---

## References

[1] Yu, Hong-Xing, et al. "Unsupervised Person Re-identification by Soft Multilabel Learning." arXiv preprint arXiv:1903.06325 (2019).
