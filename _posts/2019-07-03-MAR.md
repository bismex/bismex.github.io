---
layout: post
title: "[2019 CVPR] Unsupervised Person Re-identification by Soft Multilabel Learning (*Incomplete*)"
date: 2019-07-03 15:00:00
tags: CV re-id unsupervised
---

<!--more-->

---

**Table of content** (*full-version*)
[[paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Yu_Unsupervised_Person_Re-Identification_by_Soft_Multilabel_Learning_CVPR_2019_paper.pdf) [[github]](https://github.com/KovenYu/MAR)
{: class="table-of-content"}
* TOC
{:toc}

---

## Summary

- Unsupervised person REID 분야 (sup reid는 scalability 문제 있음)
- Soft multilabel(SM) learning: (source 도메인의 unlabeled 사람)을 (auxiliary 도메인의 labeled 참조 사람들)과 비교함으로써 soft multilabel을 부여하는 방식 (pseudo label 대신에 real-valued likelihood vector) 

<br/>
![picture]({{ '/assets/images/MAR01.png' | relative_url }})
{: style="width: 60%;" class="center"}
<span style="color: #e01f1f;">***Fig. 1. Soft multilabel learning의 컨셉***</span>

- Deep Soft Multilabel reference learning (MAR) 안에 MDL, CML, RAL 포함
  - Soft multilabel-guided discriminative embedding learning (MDL): 시각적 관점과 상대비교 특성에 대한 representation consistancy를 기반으로 soft multilabel-guided hard negative mining을 수행하고, batch마다 pos/neg set을 확보하여 pos set은 서로 가까워지도록, neg set은 멀어지도록 embedding feature를 학습하는 방법.
  - Cross-view consistent soft multilabel learning (CML): 카메라 뷰에 무관한 soft multilabel 학습을 위하여 soft multilabel 분포를 일치시키는 방법
  - Reference agent learning (RAL): 효율적인 soft multilabel 학습을 위해 joint feature embedding 안에서 참조 agent에 의한 참조 person을 나타내는 방식
--- 

## Motivation

- 기존의 방법들
  - 기존의 unsupervised reid 방법은 시각정 특징의 유사도만 보는 반면 잠재적인 레이블 정보를 보조 데이터로부터 확보한다.
  - 기존에 unsupervised DA을 기반으로하는 방법 중에서, 보조 labeled source 도메인으로부터 분별력있는 지식을 target domain으로 옮기는 방식이 있는데 이는 unlabeled source와 unlabeled target 사이의 도메인 시프트가 발생한다.
  - 그리고 일반적인 unsupervised DA에서 사용하는 같은 클래스간의 변환은 reid task와 이와 적합하지 않다.
- 본 논문의 방법은 기존의 unsupervised DA 논문들과 다르게 unlabeled target domain의 분별력있는 정보를 캐지 않은채 보조 데이터를 이용한다.

---

## Architecture

- 전체 프레임워크: 3개의 loss term (MDL, CML, RAL) 사용

<br/>
![picture]({{ '/assets/images/MAR02.png' | relative_url }})
{: style="width: 100%;" class="center"}
<span style="color: #e01f1f;">***Fig. 2. 전체 프레임워크***</span>

<p align="center">
[Notation]
</p>

{: class="info"}
| Symbol | Mean |
| ---------- | ---------- |
| $$\mathcal{X}=\left \{ x_i \right \}^{N_u}_{i=1}$$ | unlabeled target dataset (Market1501, DukeMTMC-reID)|
| $$x_i$$ | unlabeled target image |
| $$N_u$$ | the number of target images |
| $$\mathcal{Z}=\left \{ z_i, w_i \right \}^{N_a}_{i=1}$$ | labeled auxiliary (reference) dataset (MSMT17 $$\rightarrow$$ #ID-4101, #Img-126441) |
| $$z_i$$ | reference image |
| $$w_i=1, ..., N_p$$ | reference person label |
| $$N_p$$ | the number of reference persons |
| $$N_a$$ | the number of reference images |
| $$\left \{ a_i \right \}^{N_p}_{i=1}$$ | reference agents |
| $$y=l(f(x), \left \{ a_i \right \}^{N_p}_{i=1}) \in (0, 1)^{N_p}$$ | soft multilabel |
| $$l(\cdot)$$ | soft multilabel function (label likelihood w.r.t. ref. person) |
| $$f(\cdot)$$ | deep feature embedding |
| $$A(\cdot, \cdot)$$ | soft multilabel agreement |
| ---------- | ---------- |

- Soft multilabel-guided discriminative embedding learning (MDL)
  - 학습 대상 ($$f(\cdot)$$), 필요한 데이터 (positive/negative set from $$\mathcal(X)$$, reference agents $$\left \{ a_i \right \}^{N_p}_{i=1}$$)
  - Soft multilabel-guided hard negative mining 적용 이후에 unlabeled target domain에서 positive set은 서로 가까워지도록, negetive set은 멀어지도록 embedding feature를 학습하는 방법
  - Loss function
    - $$L_{MDL} = -\log \frac{\overline{P}}{\overline{P} + \overline{N}}$$
    - $$\overline{P} = \frac{1}{|\mathcal{P}|} \sum_{(i, j) \in \mathcal{P}} \exp (-\left \| f(x_i) - f(x_j) \right \|^2_2)$$
    - $$\overline{N} = \frac{1}{|\mathcal{N}|} \sum_{(k, l) \in \mathcal{N}} \exp (-\left \| f(x_k) - f(x_l) \right \|^2_2)$$
  - SM-guided hard negative mining (아래 그림 참고)
    - Unlabeled target 도메인에 대한 분별력있는 embedding feature $$f(\cdot)$$을 학습하는 방식
    - Unlabeled target pair $$(x_i, x_j)$$에서 시각적 특징 $$(f(x_i)^T f(x_j))$$과 soft multilabel agreement $$(A(y_i, y_j)=1-\frac{\left \| y_i - y_j \right \|_1}{2})$$을 보고 similarity consistency를 분석
    - 시각적으로 서로 유사하지만 (i.e., $$f(x_i)^T f(x_j)>=S$$) soft multilabel agreement이라는 다른 관점이 서로 다르다면 (i.e., $$A(y_i, y_j)<T$$) hard negative로 판단하고 두 관점 모두에서 영상이 비슷하면 positive set으로 판단
    - 한 batch (=368) 내에서 총 가능한 pair 수를 다음과 같이 표현할 때 (i.e., $$M=N_{batch} \times (N_{batch} - 1 )/2$$, $$N_{batch}$$는 한 batch 내에서 unlabeled target image의 수, 한 batch는 무작위로 샘플링한 $$x, z$$를 절반씩 구성), positive set와 negative set의 비율은 mining ratio $$p$$에 의해서 시각적으로 유사한 $$pM$$ pair 중에서 threshold $$T$$를 이용하여 조정
    - 여기에서 hypersphere leaning을 위해 $$\left \| f(\cdot) \right \|_2=1$$, $$\left \| a_i \right \|_2=1$$라고 가정 (하지만, 이는 수렴 문제 때문에 초기에는 unit norm constraint 없이 $$L_{AL}$$만 가지고 network 학습)
  

<br/>
![picture]({{ '/assets/images/MAR03.png' | relative_url }})
{: style="width: 60%;" class="center"}
<span style="color: #e01f1f;">***Fig. 3. Soft multilabel-guided hard negative mining***</span>

- Hard negative pairs에 대한 예시
  - Soft multilabel reference learning 과정을 통해 잠재적인 fine-grained discriminative 단서를 발견
  - 빨간 박스들은 한 쌍의 hard negative pair를 보여줌 (첫 줄 Market1501, 두 번째 줄 DukeMTMC-reID)
  - 빨간 박스 오른쪽 그림들은 각각 target image에서 soft label이 가장/두 번째로 높은 reference images들을 가리킴 (MSMT17)

<br/>
![picture]({{ '/assets/images/MAR04.png' | relative_url }})
{: style="width: 60%;" class="center"}
<span style="color: #e01f1f;">***Fig. 4. Soft multilabel-guided hard negative mining의 결과***</span>


- Cross-view consistent soft multilabel learning (CML)
  - 학습대상 ($$l(\cdot)$$), 필요한 데이터 ($$\mathcal(X)$$ for each camera view, reference agents $$\left \{ a_i \right \}^{N_p}_{i=1}$$)
  - 카메라 뷰에 무관한 soft multilabel 학습을 위하여 soft multilabel 분포를 일치시키는 방법
  - Loss function (simplified 2-Wasserstein distance)
    - $$L_{CML} = \sum_v \left \| \mu_v - \mu \right \|^2_2 + \left \| \sigma_v - \sigma \right \|^2_2$$
    - $$y^{(k)} = l(f(x), \left \{ a_i \right \}^{N_p}_{i=1})^{(k)} = \frac{\exp (a_k^T f(x))}{\sum_i \exp (a_i^T f(x))}$$
  - 참조 영상과의 비교 특성은 카메라 뷰에 무관하며 오로지 target domain에서 사람의 외형 분포에만 의존적이어야 함
  - 다시 말해, target domain에서 각 카메라 뷰의 soft multilabel 분포는 전체 target domain에서 soft multilabel 분포와 일치해야 함 (cross-view consistent)
  - 분포 비교를 위해서 KL-divergence를 사용해도 되고 Wasserstein distance를 사용해도 되지만 경험적으로 soft multilabel의 분포가 log-normal 분포(soft multilabel에 log를 취한 것이 normal distribution과 비슷함)를 따른다는 것을 확인하여 계산량이 적은 simplified 2-Wasserstein distance(mean vector, std vector) 이용
- Reference agent learning (RAL)
  - $$L_{RAL} = L_{AL} + \beta L_{RJ}$$
  - Agent learning loss (AL)
    - 학습대상 ($$l(\cdot), f(\cdot), \left \{ a_i \right \}^{N_p}_{i=1}$$), 필요한 데이터($$\mathcal(Z)$$, reference agents $$\left \{ a_i \right \}^{N_p}_{i=1}$$)
    - Loss function
      - $$L_{AL} = \sum_k -\log l(f(z_k), \left \{ a_i \right \})^{(w_k)} = \frac{\exp (a_{w_k}^T f(z_k))}{\sum_i \exp (a_i^T f(z_k))}$$
    - 원래 soft multilabel function은 target image와 reference agents를 비교했었지만 여기에선 $$k$$-th reference image와 그에 해당하는 label $$w_k$$를 가진 reference agent를 비교
    - 이 loss에 의해서 reference agent를 차별적으로 학습하고 feature embedding에게 기본적인 차별능력을 부여하며 (unlabeled target dataset에서는 label이 없어서 차별성을 얻기 힘듬) soft multilabel function $$l(\cdot)$$의 유효성을 암시적으로 강요함
    - Soft multilabel function의 유효성: 이 loss는 label $$w_k$$에 대한 soft label이 1이 되도록 (i.e., one-hot vector가 되도록) 학습을 지향하며 이는 이상적인 soft multilabel agreement를 생성하도록 유도함 (i.e., reference에서 같은 사람이 입력되면 agreement가 1이 됨, 다른사람이 입력되면 agreement가 0이 됨)
    - 초기에 $$f(\cdot)$$는 충분한 차별능력이 없기 때문에 unit norm constraint 없이 $$\mathcal(Z)$$만 가지고 $$L_{AL}$$를 통해 network 학습
  - Reference agent joint embedding learning loss (RJ)
    - 학습대상
    - Loss function
      - $$L_{RJ} = $$
    - AL 방법은 reference dataset에서만 적용되므로 domain gap이 존재, unlabeled target dataset에 대한 유효성이 검증되어야 함
    - 서로 다른 도메인 사이의 분포의 정렬을 위해 cross-domain hard negative pair를 수집함
    - Reference agent마다 시각적으로 비슷한 unlabeled person $$x$$를 찾은 다음에 이와 차별성을 갖도록 학습함
    - 따라서 joint embedding 학습이 필요
---

## Experimental results


<br/>
![picture]({{ '/assets/images/MAR05.png' | relative_url }})
{: style="width: 60%;" class="center"}
<span style="color: #e01f1f;">***Fig. 5. Performance comparison (Market-1501, DukeMTMC-reID)***</span>


<br/>
![picture]({{ '/assets/images/MAR06.png' | relative_url }})
{: style="width: 60%;" class="center"}
<span style="color: #e01f1f;">***Fig. 6. Ablation study***</span>



---

## References

[1] Yu, Hong-Xing, et al. "Unsupervised Person Re-identification by Soft Multilabel Learning." arXiv preprint arXiv:1903.06325 (2019).
