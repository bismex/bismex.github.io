---
layout: post
title: "[2019 CVPR] Learning to Reduce Dual-level Discrepancy for Infrared-Visible Person Re-identification"
date: 2019-06-19 20:00:00
tags: CV 
---

<!--more-->

---

**Table of content** (*full-version*)
[[paper]](http://homepage.ntu.edu.tw/~r06944046/pdf/Wang_Learning_to_Reduce_Dual-level_Discrepancy_for_Infrared-Visible_Person_Re-Identification_CVPR19.pdf)
{: class="table-of-content"}
* TOC
{:toc}

---

## Summary

- Infrared-Visible person RE-ID (IV-REID) 분야
- 문제점: appearance(APP) discrepancy + modality(MOD) discrepancy
- 기존방법: feature-level contraint 사용하여 APP+MOD 차이를 동시에 감소 시도
- 논문방법: Dual-level Discrepancy Reduction Learning (DDRL) 는 두 개의 discrepancy를 분리
  - Image-level sub-network: RGB $$\leftrightharpoons$$ IR 영상 변환으로 서로 다른 MOD를 가진 영상에 대한 표현을 통합 
  - Feature-level sub-network: 통합된 multi-spectral 영상을 가지고 feature embedding을 통해 남은 APP discrepancy를 감소
  - 두 개의 sub-network를 직렬로 jointly 학습하여 dual-level discrepancy를 협동적 + 조심스럽게 감소

---

## Motivation

- IR-REID 에서 Intra-person 사이의 간격이 Inter-person 사이의 간격보다 오히려 커서 성능이 낮음
- 이를 feature-space에서 한 번에 조정하기 힘듦
- 영상 변환을 통해 unified space로 옮긴 다음에 feature-space에서 남은 appearance의 차이를 더 줄임

<br/>
![picture]({{ '/assets/images/DDRL01.png' | relative_url }})
{: style="width: 100%;" class="center"}
<span style="color: #e01f1f;">***Fig. 1. Motivation***</span>

---

## Architecture


<p align="center">
[Notation]
</p>

{: class="info"}
| Symbol | Mean |
| ---------- | ---------- |
|  |  |
|  |  |
|  |  |
|  |  |
|  |  |
| ---------- | ---------- |


<br/>
![picture]({{ '/assets/images/DDRL02.png' | relative_url }})
{: style="width: 100%;" class="center"}
<span style="color: #e01f1f;">***Fig. 2. 전체 프레임워크***</span>


<br/>
![picture]({{ '/assets/images/DDRL03.png' | relative_url }})
{: style="width: 100%;" class="center"}
<span style="color: #e01f1f;">***Fig. 3. IV-REID 성능 비교***</span>

<br/>
![picture]({{ '/assets/images/DDRL04.png' | relative_url }})
{: style="width: 60%;" class="center"}
<span style="color: #e01f1f;">***Fig. 4. Ablation study***</span>

<br/>
![picture]({{ '/assets/images/DDRL05.png' | relative_url }})
{: style="width: 100%;" class="center"}
<span style="color: #e01f1f;">***Fig. 5. Intra-person, inter-person의 feature-space distribution***</span>


<br/>
![picture]({{ '/assets/images/DDRL06.png' | relative_url }})
{: style="width: 100%;" class="center"}
<span style="color: #e01f1f;">***Fig. 6. Image-space 변환결과***</span>

<br/>
![picture]({{ '/assets/images/DDRL07.png' | relative_url }})
{: style="width: 100%;" class="center"}
<span style="color: #e01f1f;">***Fig. 7. Failure case***</span>



---
  
## Experimental results

---

## Comments

---

## References

[1] Wang, Zhixiang, et al. "Learning to Reduce Dual-level Discrepancy for Infrared-Visible Person Re-identification." Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. Vol. 2. No. 3. 2019.
