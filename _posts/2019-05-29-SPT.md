---
layout: post
title: "[2019 CVPR] Unsupervised Person Image Generation with Semantic Parsing Transformation (*incomplete*)"
date: 2019-05-29 19:00:00
tags: CV re-id unsupervised
---

<!--more-->

---

**Table of content** (*full-version*)
[[paper]](https://arxiv.org/pdf/1904.03379.pdf) [[github]](https://github.com/SijieSong/person_generation_spt)
{: class="table-of-content"}
* TOC
{:toc}

---

## Summary

- Unsupervised (unpaired) + end-to end pose-guided person image generation (challenging due to non-rigid deformation)
- 기존의 rock-hard direct mapping 방법을 두개의 가능한 서브 task로 분할
  - semantic generative network: non-regid deformation learning을 간단화하기 위해서 target pose에 따라서 semantic parsing map을 변환
  - Appearance generative network: 변환된 semantic parsing map에 semantic-aware texture를 합성 (semantic-aware style loss 이용)
- 기타 방법들: semantic parsing을 위한 pseudo labeling 방법, 학습에 사용되는 cycle consistency, end-to-end manner

---

## Motivation

- 기존의 방법들
  - Paired supervision을 많이 사용 $$\rightarrow$$ data 부족 문제로 unpaired 방법 발전 (그러나 성능은 아직)
  - Disentanglement 방식도 제안 $$\rightarrow$$ non-rigid human body deformation and clothing shape를 무시하면 좋은 성능 못냄
- 완전한 unsupervised 방식(unpaired)의 어려움
  - 인간의 몸은 non-rigid deformation이므로 공간적으로 정렬되지 않은 몸을 변환하는 것은 현재의 conv기반 네트워크에서 어렵다
  - 다른 포즈를 생성하는 동안 옷의 특성을 보존하기 어렵다
  - pair 영상을 활용하지 못하므로 효율적인 학습 목적을 달성하기 힘들다
- 이를 해결하기 위해 비교적 쉬운 사람 영상과 semantic parsing 사이의 관계를 이용한다.

---

## Architecture


<p align="center">
[Notation]
</p>

{: class="info"}
| Symbol | Mean |
| ---------- | ---------- |
| $$I_{P_s}$$ | source image |
| $$\tilde{I}_{P_s}$$ | predicted source image by mapped-back (cycle consistency) |
| $$\tilde{I}_{P_t}$$ | predicted target image |
| $$P_s$$ | source pose (2D pose by OpenPose[2] $$\rightarrow$$ 18-dimension heat map) 
| $$P_t$$ | target pose |
| $$P^*_t$$ | pseudo target pose by affined transformation) |
| $$M_{P_s}$$ | source pose mask (same definition in [3]) |
| $$M_{P_t}$$ | target pose mask |
| $$M_{P^*_t}$$ | target pose mask |
| $$S_{P_s}$$ | source semantic map (Human parser[4]: 10 labels, $${0, 1}^{10 \times H \times W}$$) |
| $$\tilde{S}_{P_s}$$ | predicted source semantic map by mapped-back (cycle consistency) |
| $$\tilde{S}_{P_t}$$ | predicted target semantic map |
| $$S_{P^*_t}$$ | pseudo target semantic map by $$P^*_t$$|
| ---------- | ---------- |
| $$H_S$$ | semantic generator |
| $$E_S$$ | semantic map encoder |
| $$E_P$$ | pose encoder |
| $$G_S$$ | semantic map generator |
| $$D_S$$ | semantic map discriminator |
| $$H_A$$ | appearance generator |
| $$E_A$$ | appearance encoder |
| $$E'_s$$ | semantic map encoder |
| $$G_A$$ | appearance generator |
| $$D_A$$ | appearance discriminator |
| $$D_F$$ | face discriminator |
| ---------- | ---------- |

- 전체 프레임워크
  - Unsupervised 방식
    - 보유한 것: {$$I_{P_s}$$, $$P_s$$, $$M_{P_s}$$, $$S_{P_s}$$}, {$$P^*_t$$, $$M_{P^*_t}$$, $$S_{P^*_t}$$}
    - 찾아야 하는 것: {$$\tilde{S}_{P_t}$$, $$\tilde{I}_{P_t}$$}, {$$\tilde{S}_{P_s}$$, $$\tilde{I}_{P_s}$$} for cycle consistency
  - 순방향: 
  - 역방향: 
- Loss function


<br/>
![picture]({{ '/assets/images/SPT01.png' | relative_url }})
{: style="width: 100%;" class="center"}
<span style="color: #e01f1f;">***Fig. 1. 전체 프레임워크***</span>

---
  
## Experimental results


<br/>
![picture]({{ '/assets/images/SPT02.png' | relative_url }})
{: style="width: 60%;" class="center"}
<span style="color: #e01f1f;">***Fig. 2. 사람 생성 모델관련 여러가지 방법들과의 성능비교 (Deep fashion)***</span>


<br/>
![picture]({{ '/assets/images/SPT03.png' | relative_url }})
{: style="width: 60%;" class="center"}
<span style="color: #e01f1f;">***Fig. 3. 사람 생성 모델관련 여러가지 방법들과의 성능비교 (Market-1501)***</span>



<br/>
![picture]({{ '/assets/images/SPT04.png' | relative_url }})
{: style="width: 100%;" class="center"}
<span style="color: #e01f1f;">***Fig. 4. Ablation study (network training)***</span>

<br/>
![picture]({{ '/assets/images/SPT05.png' | relative_url }})
{: style="width: 60%;" class="center"}
<span style="color: #e01f1f;">***Fig. 5. Ablation study (loss function)***</span>


<br/>
![picture]({{ '/assets/images/SPT06.png' | relative_url }})
{: style="width: 60%;" class="center"}
<span style="color: #e01f1f;">***Fig. 6. Texture transfer 응용***</span>



<br/>
![picture]({{ '/assets/images/SPT07.png' | relative_url }})
{: style="width: 60%;" class="center"}
<span style="color: #e01f1f;">***Fig. 7. Controlled image manipulation 응용***</span>



<br/>
![picture]({{ '/assets/images/SPT08.png' | relative_url }})
{: style="width: 60%;" class="center"}
<span style="color: #e01f1f;">***Fig. 8. Failure case***</span>


---

## Comments

---

## References

[1] Song, Sijie, et al. "Unsupervised Person Image Generation with Semantic Parsing Transformation." arXiv preprint arXiv:1904.03379 (2019).

[2] Zhe Cao, Tomas Simon, Shih-En Wei, and Yaser Sheikh. Realtime multi-person 2d pose estimation using part affinity fields. In Proc. IEEE Conference on Computer Vision and Pattern Recognition, 2017.

[3] Liqian Ma, Xu Jia, Qianru Sun, Bernt Schiele, Tinne Tuytelaars, and Luc Van Gool. Pose guided person image generation. In Proc. Advances in Neural Information Processing Systems, 2017

[4] Ke Gong, Xiaodan Liang, Dongyu Zhang, Xiaohui Shen, and Liang Lin. Look into person: Self-supervised structure sensitive learning and a new benchmark for human parsing. In Proc. IEEE Conference on Computer Vision and Pattern Recognition, 2017.

[5]

[6]
