---
layout: post
title: "[2019 CVPR] Unsupervised Person Image Generation with Semantic Parsing Transformation (*incomplete*)"
date: 2019-05-29 19:00:00
tags: CV re-id unsupervised
---

<!--more-->

---

**Table of content** (*full-version*)
[[paper]](https://arxiv.org/pdf/1904.03379.pdf) [[github]](https://github.com/SijieSong/person_generation_spt)
{: class="table-of-content"}
* TOC
{:toc}

---

## Summary

- Unsupervised (unpaired) + end-to end pose-guided person image generation (challenging due to non-rigid deformation)
- 기존의 rock-hard direct mapping 방법을 두개의 가능한 서브 task로 분할
  - Semantic generative network: non-regid deformation learning을 간단화하기 위해서 target pose에 따라서 semantic parsing map을 변환
  - Appearance generative network: 변환된 semantic parsing map에 semantic-aware texture를 합성 (semantic-aware style loss 이용)
- 기타 방법들: semantic parsing을 위한 pseudo labeling 방법, 학습에 사용되는 cycle consistency, end-to-end manner

---

## Motivation

- 기존의 방법들
  - Paired supervision을 많이 사용 $$\rightarrow$$ data 부족 문제로 unpaired 방법 발전 (그러나 성능은 아직)
  - Disentanglement 방식도 제안 $$\rightarrow$$ non-rigid human body deformation and clothing shape를 무시하면 좋은 성능 못냄
- 완전한 unsupervised 방식(unpaired)의 어려움
  - 인간의 몸은 non-rigid deformation이므로 공간적으로 정렬되지 않은 몸을 변환하는 것은 현재의 conv기반 네트워크에서 어렵다
  - 다른 포즈를 생성하는 동안 옷의 특성을 보존하기 어렵다
  - pair 영상을 활용하지 못하므로 효율적인 학습 목적을 달성하기 힘들다
- 이를 해결하기 위해 비교적 쉬운 사람 영상과 semantic parsing 사이의 관계를 이용한다.

---

## Architecture


<p align="center">
[Notation]
</p>

{: class="info"}
| Symbol | Mean |
| ---------- | ---------- |
| $$I_{P_s}$$ | source image |
| $$\tilde{I}_{P_s}$$ | predicted source image by mapped-back (cycle consistency) |
| $$\tilde{I}_{P_t}$$ | predicted target image |
| $$P_s$$ | source pose (2D pose by OpenPose[2] $$\rightarrow$$ 18-dimension heat map) 
| $$P_t$$ | target pose (pseudo pose by affine transformation) |
| $$M_{P_s}$$ | source pose mask (same definition in [3]) to help generate continuous semantic maps |
| $$M_{P_t}$$ | target pose mask (pseudo mask) |
| $$S_{P_s}$$ | source semantic map (Human parser[4]: 10 labels, $${0, 1}^{10 \times H \times W}$$) |
| $$S_{P_t}$$ | target semantic map (pseudo ground truth) |
| $$\tilde{S}_{P_s}$$ | predicted source semantic map by mapped-back (cycle consistency) |
| $$\tilde{S}_{P_t}$$ | predicted target semantic map |
| ---------- | ---------- |
| $$H_S$$ | semantic generator |
| $$E_S$$ | semantic map encoder |
| $$E_P$$ | pose encoder |
| $$G_S$$ | semantic map generator |
| $$D_S$$ | semantic map discriminator |
| $$H_A$$ | appearance generator |
| $$E_A$$ | appearance encoder |
| $$E'_s$$ | semantic map encoder |
| $$G_A$$ | appearance generator |
| $$D_A$$ | appearance discriminator |
| $$D_F$$ | face discriminator |
| ---------- | ---------- |

- 전체 프레임워크
  - Unsupervised 방식 ({$$\tilde{S}_{P_t}$$, $$\tilde{I}_{P_t}$$} 를 이용하지 않음)
    - 기본적으로 보유한 것: {$$I_{P_s}$$}
    - Additional 추정한 것: {$$P_s$$, $$M_{P_s}$$, $$S_{P_s}$$}
    - Pseudo labeling한 것: {$$P^*_t$$, $$M_{P^*_t}$$, $$S_{P^*_t}$$}
    - 찾아야 하는 것: {$$\tilde{S}_{P_t}$$, $$\tilde{I}_{P_t}$$}, {$$\tilde{S}_{P_s}$$, $$\tilde{I}_{P_s}$$} for cycle consistency
  - 순방향: 
$$
&\tilde{S}_{P_t} = G_S (E_S (S_{P_s}, P_s, M_{P_s}), E_P (P_t, M_{P_t}))& \\
&\tilde{I}_{P_t} = G_A (E_A (I_{P_s}, P_s, S_{P_s}), E'_S (P_t, \tilde{S}_{P_t})) &
$$
  - 역방향: 
$$
&\tilde{S}_{P_s} = G_S (E_S (\tilde{S}_{P_t}, P_t, M_{P_t}), E_P (P_s, M_{P_s}))& \\
&\tilde{I}_{P_s} = G_A (E_A (\tilde{I}_{P_t}, P_t, \tilde{S}_{P_t}), E'_S (P_s, \tilde{S}_{P_s})) &
$$
- Loss function
  - Semantic parsing transformation
    - Network: $$\tilde{S}_{P_t} = G_S (E_S (S_{P_s}, P_s, M_{P_s}), E_P (P_t, M_{P_t}))$$
    - Semantic map을 출력하기 위해서 Generator 뒤에 각 픽셀마다 softmax activation function을 적용
    - $$S_{P_t}$$이 따로 없기에 학습에 용이하도록 pseudo labeling 적용 ($$S_{P^*_t}$$)
    - $$S$$에는 옷 정보가 없으므로 $$S_{P_s}$$를 기반으로 $$S_{P^*_t}$$를 생성한다.
    - [5] 에서 사용한 것처럼 10개의 rigid body subparts를 나누어 binary mask를 형성한다. $${B^j}^10_{j=1}$$
    - 이 binary mask와 affine transformation을 이용하여 새로운 포즈 새로운 semantic mask를 형성한다. (이때 너부 포즈가 비슷하면 배제)
    - Eq: $$S_{P^*_t} = \arg\min_{S_p} \sum^{10}_{j=1} \left \| B^j_p \bigotimes S_p - f_j (B^j_{P_s} \bigotimes S_{P_s})  \right \|^2_2$$
    - Loss
      - Cross entrophy loss: $$L^{adv}_S = L^{adv} (G_s \circ (E_S, E_P), D_S, S_{P^*_t}, \tilde{S}_{P^*_t}) = \mathbb{E}_{S_{P^*_t}} [\log D_S (S_{P^*_t})] + \mathbb{E_{S_{P^*_t}} [\log ( - D_S (\tilde{S}_{P^*_t}) ]$$
        - Pseudo label에 의해서 paired data 생성 $${S_{P_s}, P_s, S_{P^*_t}, P^*_t}$$
        - $$\tilde{S}_{P_t}$$가 잘 추정되도록 pixel-level accuracy 측정 
      - Adversarial loss
  - Appearance generation
    - Network: $$\tilde{I}_{P_t} = G_A (E_A (I_{P_s}, P_s, S_{P_s}), E'_S (P_t, \tilde{S}_{P_t}))$$
    - 


<br/>
![picture]({{ '/assets/images/SPT01.png' | relative_url }})
{: style="width: 100%;" class="center"}
<span style="color: #e01f1f;">***Fig. 1. 전체 프레임워크***</span>

---
  
## Experimental results


<br/>
![picture]({{ '/assets/images/SPT02.png' | relative_url }})
{: style="width: 60%;" class="center"}
<span style="color: #e01f1f;">***Fig. 2. 사람 생성 모델관련 여러가지 방법들과의 성능비교 (Deep fashion)***</span>


<br/>
![picture]({{ '/assets/images/SPT03.png' | relative_url }})
{: style="width: 60%;" class="center"}
<span style="color: #e01f1f;">***Fig. 3. 사람 생성 모델관련 여러가지 방법들과의 성능비교 (Market-1501)***</span>



<br/>
![picture]({{ '/assets/images/SPT04.png' | relative_url }})
{: style="width: 100%;" class="center"}
<span style="color: #e01f1f;">***Fig. 4. Ablation study (network training)***</span>

<br/>
![picture]({{ '/assets/images/SPT05.png' | relative_url }})
{: style="width: 60%;" class="center"}
<span style="color: #e01f1f;">***Fig. 5. Ablation study (loss function)***</span>


<br/>
![picture]({{ '/assets/images/SPT06.png' | relative_url }})
{: style="width: 60%;" class="center"}
<span style="color: #e01f1f;">***Fig. 6. Texture transfer 응용***</span>



<br/>
![picture]({{ '/assets/images/SPT07.png' | relative_url }})
{: style="width: 60%;" class="center"}
<span style="color: #e01f1f;">***Fig. 7. Controlled image manipulation 응용***</span>



<br/>
![picture]({{ '/assets/images/SPT08.png' | relative_url }})
{: style="width: 60%;" class="center"}
<span style="color: #e01f1f;">***Fig. 8. Failure case***</span>


---

## Comments

---

## References

[1] Song, Sijie, et al. "Unsupervised Person Image Generation with Semantic Parsing Transformation." arXiv preprint arXiv:1904.03379 (2019).

[2] Zhe Cao, Tomas Simon, Shih-En Wei, and Yaser Sheikh. Realtime multi-person 2d pose estimation using part affinity fields. In Proc. IEEE Conference on Computer Vision and Pattern Recognition, 2017.

[3] Liqian Ma, Xu Jia, Qianru Sun, Bernt Schiele, Tinne Tuytelaars, and Luc Van Gool. Pose guided person image generation. In Proc. Advances in Neural Information Processing Systems, 2017

[4] Ke Gong, Xiaodan Liang, Dongyu Zhang, Xiaohui Shen, and Liang Lin. Look into person: Self-supervised structure sensitive learning and a new benchmark for human parsing. In Proc. IEEE Conference on Computer Vision and Pattern Recognition, 2017.

[5] Aliaksandr Siarohin, Enver Sangineto, St´ephane Lathuili`ere, and Nicu Sebe. Deformable gans for pose-based human image generation. In Proc. IEEE Conference on Computer Vision and Pattern Recognition, 2018.

[6]
